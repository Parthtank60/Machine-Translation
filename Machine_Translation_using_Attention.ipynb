{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Translation using Attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVNqy1OVMKVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn8ZJWHFMaON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5871aede-46e8-4c00-dfb2-8e9aee818901"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qPptsl4Mmb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "0bc87875-f965-4304-e208-e51205d8d4f5"
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Barrons-800.gdoc\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            " Content-Based-Video-Search-TCS.zip\n",
            "'datasets links'\n",
            " fra.txt\n",
            "'[GigaCourse.com] Udemy - Deep Learning and Computer Vision A-Z™ OpenCV, SSD & GANs'\n",
            " glove.6B.100d.txt\n",
            " gre\n",
            "'How to get started with Drive.pdf'\n",
            " Icons\n",
            " ipgm_project\n",
            "'jigsaw toxic'\n",
            " magoos\n",
            "'Mike And Dave Need Wedding Dates (2016) [1080p] [YTS.AG]'\n",
            "'ml resume'\n",
            " project\n",
            "'Research papers (final-year project).gsheet'\n",
            "'resume certificates.pdf'\n",
            " resume.pdf\n",
            " TCS_PROJECT\n",
            " Untitled0.ipynb\n",
            "'Untitled document.gdoc'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " videos\n",
            " YOLOv3-Object-Detection-with-OpenCV\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kistygB2MucG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "943d43d7-69b2-4dd5-99f7-ad33d5451662"
      },
      "source": [
        "# https://deeplearningcourses.com/c/deep-learning-advanced-nlp\n",
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "import os, sys\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
        "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras.backend as K\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
        "#   from keras.layers import CuDNNLSTM as LSTM\n",
        "#   from keras.layers import CuDNNGRU as GRU\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91Yl7MV0MzJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_over_time(x):\n",
        "  assert(K.ndim(x) > 2)\n",
        "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
        "  s = K.sum(e, axis=1, keepdims=True)\n",
        "  return e / s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BOeTvkXNVIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# config\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "LATENT_DIM = 400\n",
        "LATENT_DIM_DECODER = 400 # idea: make it different to ensure things all fit together properly!\n",
        "NUM_SAMPLES = 20000\n",
        "MAX_SEQUENCE_LENGTH = 100\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Where we will store the data\n",
        "input_texts = [] # sentence in original language\n",
        "target_texts = [] # sentence in target language\n",
        "target_texts_inputs = [] # sentence in target language offset by 1\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRe9H-lBNX5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08426e2f-a9a7-4989-dc55-b48cf819333a"
      },
      "source": [
        "# load in the data\n",
        "# download the data at: http://www.manythings.org/anki/\n",
        "t = 0\n",
        "for line in open('/content/drive/My Drive/fra.txt'):\n",
        "  # only keep a limited number of samples\n",
        "  t += 1\n",
        "  if t > NUM_SAMPLES:\n",
        "    break\n",
        "\n",
        "  # input and target are separated by tab\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "\n",
        "  # split up the input and translation\n",
        "  input_text, translation, *rest = line.rstrip().split('\\t')\n",
        "\n",
        "  # make the target input and output\n",
        "  # recall we'll be using teacher forcing\n",
        "  target_text = translation + ' <eos>'\n",
        "  target_text_input = '<sos> ' + translation\n",
        "\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  target_texts_inputs.append(target_text_input)\n",
        "print(\"num samples:\", len(input_texts))\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples: 20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPJj5wnWN6Ty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a4856c0-4232-4be5-b1ab-e874160d7c60"
      },
      "source": [
        "# tokenize the inputs\n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
        "\n",
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# determine maximum length input sequence\n",
        "max_len_input = max(len(s) for s in input_sequences)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3514 unique input tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXg6PxqhOGXH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33c196dc-7c0a-4930-e356-c044f0b78cf3"
      },
      "source": [
        "# tokenize the outputs\n",
        "# don't filter out special characters\n",
        "# otherwise <sos> and <eos> won't appear\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "# determine maximum length output sequence\n",
        "max_len_target = max(len(s) for s in target_sequences)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9532 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_kG4FhBOLne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "43b11c54-2182-4aa8-9999-f4c2f2207784"
      },
      "source": [
        "\n",
        "# pad the sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_data[0]:\", encoder_inputs[0])\n",
        "\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_data.shape:\", decoder_inputs.shape)\n",
        "\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_data.shape: (20000, 6)\n",
            "encoder_data[0]: [ 0  0  0  0  0 20]\n",
            "decoder_data[0]: [ 2 65  5  0  0  0  0  0  0  0  0  0  0]\n",
            "decoder_data.shape: (20000, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caAyUE10Obnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5496e1a1-c021-451d-a3a5-de1780efc1c0"
      },
      "source": [
        "# store all the pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open('/content/drive/My Drive/glove.6B.100d.txt') as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xwnSbvtOr5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b138f6e4-347d-478a-c20e-e2efa90e8f8e"
      },
      "source": [
        "# prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < MAX_NUM_WORDS:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH8P_MpvO7aE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create embedding layer\n",
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_len_input,\n",
        "  # trainable=True\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMShKc4HPBWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create targets, since we cannot use sparse\n",
        "# categorical cross entropy when we have sequences\n",
        "decoder_targets_one_hot = np.zeros(\n",
        "  (\n",
        "    len(input_texts),\n",
        "    max_len_target,\n",
        "    num_words_output\n",
        "  ),\n",
        "  dtype='float32'\n",
        ")\n",
        "\n",
        "# assign the values\n",
        "for i, d in enumerate(decoder_targets):\n",
        "  for t, word in enumerate(d):\n",
        "    if word > 0:\n",
        "      decoder_targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5ZroJfOFwpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "74f7fb0f-2eab-4cc5-f29a-162b169ce471"
      },
      "source": [
        "##### build the model #####\n",
        "print(\"h\")\n",
        "# Set up the encoder - simple!\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "print(x.shape)\n",
        "encoder = Bidirectional(LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_sequences=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        "))\n",
        "encoder_outputs = encoder(x)\n",
        "print(encoder_outputs.shape)\n",
        "\n",
        "\n",
        "# Set up the decoder - not so simple\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "print(decoder_inputs_placeholder.shape)\n",
        "# this word embedding will not use pre-trained vectors\n",
        "# although you could\n",
        "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "print(decoder_inputs_x.shape)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h\n",
            "(None, 6, 100)\n",
            "(None, 6, 800)\n",
            "(None, 13)\n",
            "(None, 13, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5r1ZrIu-Byf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######### Attention #########\n",
        "# Attention layers need to be global because\n",
        "# they will be repeated Ty times at the decoder\n",
        "attn_repeat_layer = RepeatVector(max_len_input)\n",
        "attn_concat_layer = Concatenate(axis=-1)\n",
        "attn_dense1 = Dense(10, activation='tanh')\n",
        "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
        "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n",
        "\n",
        "def one_step_attention(h, st_1):\n",
        "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
        "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
        " \n",
        "  # copy s(t-1) Tx times\n",
        "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
        "  st_1 = attn_repeat_layer(st_1)\n",
        "  print(st_1.shape)\n",
        "\n",
        "  # Concatenate all h(t)'s with s(t-1)\n",
        "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
        "  x = attn_concat_layer([h, st_1])\n",
        "  print(x.shape)\n",
        "  # Neural net first layer\n",
        "  x = attn_dense1(x)\n",
        "  print(x.shape)\n",
        "\n",
        "  # Neural net second layer with special softmax over time\n",
        "  alphas = attn_dense2(x)\n",
        "  print(alphas.shape)\n",
        "\n",
        "  # \"Dot\" the alphas and the h's\n",
        "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
        "  context = attn_dot([alphas, h])\n",
        "  print(context.shape)\n",
        "\n",
        "  return context\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npW1Y9U1-4TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the rest of the decoder (after attention)\n",
        "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "\n",
        "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
        "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
        "context_last_word_concat_layer = Concatenate(axis=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRIndRF5_PYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c09dd5d-73a6-47eb-e28d-0cbb04d708e2"
      },
      "source": [
        "print(initial_s.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks4La6YI_btA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# s, c will be re-assigned in each iteration of the loop\n",
        "s = initial_s\n",
        "c = initial_c\n",
        "\n",
        "# collect outputs in a list at first\n",
        "outputs = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkhaoEF7_tB5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f44cfec6-3bd7-4226-9edb-7f77a63a0b5e"
      },
      "source": [
        "\n",
        "for t in range(max_len_target): # Ty times\n",
        "  # get the context using attention\n",
        "  context = one_step_attention(encoder_outputs, s)\n",
        "\n",
        "  # we need a different layer for each time step\n",
        "  selector = Lambda(lambda x: x[:, t:t+1])\n",
        "  xt = selector(decoder_inputs_x)\n",
        "  \n",
        "  # combine \n",
        "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
        "\n",
        "  # pass the combined [context, last word] into the LSTM\n",
        "  # along with [s, c]\n",
        "  # get the new [s, c] and output\n",
        "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
        "\n",
        "  # final dense layer to get next word prediction\n",
        "  decoder_outputs = decoder_dense(o)\n",
        "  outputs.append(decoder_outputs)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO4wIjaGAtzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b82e5ec4-4196-4db3-cb05-3d21ac9703e5"
      },
      "source": [
        "print(xt.shape)\n",
        "print(decoder_lstm_input.shape)\n",
        "print(o.shape)\n",
        "print(s.shape)\n",
        "print(c.shape)\n",
        "print(decoder_outputs.shape)\n",
        "print(outputs)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 1, 100)\n",
            "(None, 1, 900)\n",
            "(None, 400)\n",
            "(None, 400)\n",
            "(None, 400)\n",
            "(None, 9533)\n",
            "[<tf.Tensor 'dense_6/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_1/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_2/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_3/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_4/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_5/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_6/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_7/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_8/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_9/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_10/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_11/Softmax:0' shape=(None, 9533) dtype=float32>, <tf.Tensor 'dense_6_12/Softmax:0' shape=(None, 9533) dtype=float32>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_0OQscGBVE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'outputs' is now a list of length Ty\n",
        "# each element is of shape (batch size, output vocab size)\n",
        "# therefore if we simply stack all the outputs into 1 tensor\n",
        "# it would be of shape T x N x D\n",
        "# we would like it to be of shape N x T x D\n",
        "\n",
        "def stack_and_transpose(x):\n",
        "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
        "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
        "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL3m0LdeCpFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd75260e-83e5-422e-c320-11079bae904f"
      },
      "source": [
        "# make it a layer\n",
        "stacker = Lambda(stack_and_transpose)\n",
        "outputs = stacker(outputs)\n",
        "print(outputs.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 13, 9533)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnOeirXbCv7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model\n",
        "model = Model(\n",
        "  inputs=[\n",
        "    encoder_inputs_placeholder,\n",
        "    decoder_inputs_placeholder,\n",
        "    initial_s, \n",
        "    initial_c,\n",
        "  ],\n",
        "  outputs=outputs\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alJImC47C0CK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "  # both are of shape N x T x K\n",
        "  mask = K.cast(y_true > 0, dtype='float32')\n",
        "  out = mask * y_true * K.log(y_pred)\n",
        "  return -K.sum(out) / K.sum(mask)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYyoI6agC_AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(y_true, y_pred):\n",
        "  # both are of shape N x T x K\n",
        "  targ = K.argmax(y_true, axis=-1)\n",
        "  pred = K.argmax(y_pred, axis=-1)\n",
        "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
        "\n",
        "  # 0 is padding, don't include those\n",
        "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
        "  n_correct = K.sum(mask * correct)\n",
        "  n_total = K.sum(mask)\n",
        "  return n_correct / n_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_lH3FyxDBCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])\n",
        "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2kl2KQkDDS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72ed40d7-20cf-4eb0-f244-e73de39e6172"
      },
      "source": [
        "# train the model\n",
        "z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER)) # initial [s, c]\n",
        "print(z.shape)\n",
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 400)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 16000 samples, validate on 4000 samples\n",
            "Epoch 1/30\n",
            "16000/16000 [==============================] - 38s 2ms/step - loss: 5.9843 - acc: 0.2376 - val_loss: 5.9434 - val_acc: 0.2237\n",
            "Epoch 2/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 5.1457 - acc: 0.2743 - val_loss: 5.5162 - val_acc: 0.2345\n",
            "Epoch 3/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 4.6278 - acc: 0.3051 - val_loss: 4.8828 - val_acc: 0.3041\n",
            "Epoch 4/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 3.7067 - acc: 0.4358 - val_loss: 4.1965 - val_acc: 0.4033\n",
            "Epoch 5/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 2.9967 - acc: 0.5089 - val_loss: 3.9223 - val_acc: 0.4430\n",
            "Epoch 6/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 2.4848 - acc: 0.5505 - val_loss: 3.7840 - val_acc: 0.4621\n",
            "Epoch 7/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 2.0645 - acc: 0.5901 - val_loss: 3.6949 - val_acc: 0.4721\n",
            "Epoch 8/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 1.7165 - acc: 0.6301 - val_loss: 3.6757 - val_acc: 0.4793\n",
            "Epoch 9/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 1.4257 - acc: 0.6705 - val_loss: 3.6397 - val_acc: 0.4874\n",
            "Epoch 10/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 1.1844 - acc: 0.7093 - val_loss: 3.6156 - val_acc: 0.4976\n",
            "Epoch 11/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.9883 - acc: 0.7470 - val_loss: 3.6178 - val_acc: 0.4991\n",
            "Epoch 12/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.8319 - acc: 0.7778 - val_loss: 3.6245 - val_acc: 0.5056\n",
            "Epoch 13/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.7099 - acc: 0.8015 - val_loss: 3.6339 - val_acc: 0.5103\n",
            "Epoch 14/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.6119 - acc: 0.8216 - val_loss: 3.6479 - val_acc: 0.5074\n",
            "Epoch 15/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.5369 - acc: 0.8349 - val_loss: 3.6727 - val_acc: 0.5099\n",
            "Epoch 16/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.4804 - acc: 0.8463 - val_loss: 3.6600 - val_acc: 0.5144\n",
            "Epoch 17/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.4378 - acc: 0.8515 - val_loss: 3.6927 - val_acc: 0.5164\n",
            "Epoch 18/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.4031 - acc: 0.8582 - val_loss: 3.7173 - val_acc: 0.5151\n",
            "Epoch 19/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.3758 - acc: 0.8621 - val_loss: 3.7489 - val_acc: 0.5146\n",
            "Epoch 20/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.3554 - acc: 0.8662 - val_loss: 3.7669 - val_acc: 0.5185\n",
            "Epoch 21/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.3391 - acc: 0.8677 - val_loss: 3.7682 - val_acc: 0.5157\n",
            "Epoch 22/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.3266 - acc: 0.8686 - val_loss: 3.8056 - val_acc: 0.5166\n",
            "Epoch 23/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.3163 - acc: 0.8707 - val_loss: 3.8124 - val_acc: 0.5166\n",
            "Epoch 24/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.3061 - acc: 0.8724 - val_loss: 3.8438 - val_acc: 0.5161\n",
            "Epoch 25/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.2998 - acc: 0.8729 - val_loss: 3.8610 - val_acc: 0.5157\n",
            "Epoch 26/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.2947 - acc: 0.8727 - val_loss: 3.8922 - val_acc: 0.5141\n",
            "Epoch 27/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.2876 - acc: 0.8747 - val_loss: 3.8890 - val_acc: 0.5126\n",
            "Epoch 28/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.2844 - acc: 0.8748 - val_loss: 3.9099 - val_acc: 0.5176\n",
            "Epoch 29/30\n",
            "16000/16000 [==============================] - 33s 2ms/step - loss: 0.2798 - acc: 0.8746 - val_loss: 3.9170 - val_acc: 0.5155\n",
            "Epoch 30/30\n",
            "16000/16000 [==============================] - 32s 2ms/step - loss: 0.2768 - acc: 0.8747 - val_loss: 3.9132 - val_acc: 0.5167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B1JGGrMDP2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e9c4b3a0-6eab-41c6-964b-2f34a2095631"
      },
      "source": [
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TluOleATJ2rF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "3bb9e9d1-6234-41c8-bf52-2f799b9e663b"
      },
      "source": [
        "# accuracies\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-a0a7d784daeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr_cjUd0J4bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # The encoder will be stand-alone\n",
        "# From this we will get our initial decoder hidden state\n",
        "# i.e. h(1), ..., h(Tx)\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJB5UvNuO9U_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "899e8c89-fd84-4dc2-e7d8-73a27d67d84c"
      },
      "source": [
        "# next we define a T=1 decoder model\n",
        "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
        "print(encoder_outputs_as_input.shape)\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "print(decoder_inputs_single.shape)\n",
        "\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "print(decoder_inputs_single_x.shape)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 6, 800)\n",
            "(None, 1)\n",
            "(None, 1, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDQH0gjyPAwW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "72f0b63d-d5aa-48d1-c9f2-3d9710a64ef9"
      },
      "source": [
        "# no need to loop over attention steps this time because there is only one step\n",
        "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
        "print(context.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 6, 400)\n",
            "(None, 6, 1200)\n",
            "(None, 6, 10)\n",
            "(None, 6, 1)\n",
            "(None, 1, 800)\n",
            "(None, 1, 800)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaL3nMq6Pb-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5907804-7301-4726-a42d-35880e055c96"
      },
      "source": [
        "# combine context with last word\n",
        "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
        "print(decoder_lstm_input.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 1, 900)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3LCDtB3Pp3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "552c9a03-7295-48e7-9cc2-6b3f09067212"
      },
      "source": [
        "# lstm and final dense\n",
        "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
        "print(o.shape)\n",
        "print(s.shape)\n",
        "print(c.shape)\n",
        "\n",
        "decoder_outputs = decoder_dense(o)\n",
        "print(decoder_outputs.shape)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 400)\n",
            "(None, 400)\n",
            "(None, 400)\n",
            "(None, 9533)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGy4YZVXP_Pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the model object\n",
        "decoder_model = Model(\n",
        "  inputs=[\n",
        "    decoder_inputs_single,\n",
        "    encoder_outputs_as_input,\n",
        "    initial_s, \n",
        "    initial_c\n",
        "  ],\n",
        "  outputs=[decoder_outputs, s, c]\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUGrWxyjQP_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLbZDmjcSDGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  enc_out = encoder_model.predict(input_seq)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  \n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = word2idx_outputs['<eos>']\n",
        "\n",
        "\n",
        "  # [s, c] will be updated in each loop iteration\n",
        "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
        "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
        "\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
        "        \n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(o.flatten())\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "  return ' '.join(output_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU4pg3czTg01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "2c2a834c-bd3b-4671-dad9-362787620e39"
      },
      "source": [
        "while True:\n",
        "  # Do some test translations\n",
        "  i = np.random.choice(len(input_texts))\n",
        "  input_seq = encoder_inputs[i:i+1]\n",
        "  translation = decode_sequence(input_seq)\n",
        "  print('-')\n",
        "  print('Input sentence:', input_texts[i])\n",
        "  print('Predicted translation:', translation)\n",
        "  print('Actual translation:', target_texts[i])\n",
        "\n",
        "  ans = input(\"Continue? [Y/n]\")\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "    break"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: I got divorced.\n",
            "Predicted translation: j'ai divorcé.\n",
            "Actual translation: J'ai divorcé. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: Sit down, Tom.\n",
            "Predicted translation: asseyez-vous, tom.\n",
            "Actual translation: Asseyez-vous, Tom. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: We can't escape.\n",
            "Predicted translation: nous ne pouvons nous échapper.\n",
            "Actual translation: Nous ne pouvons nous échapper. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: Now I'm serious.\n",
            "Predicted translation: maintenant je suis sérieux.\n",
            "Actual translation: Maintenant je suis sérieux. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: He is a poet.\n",
            "Predicted translation: c'est un poète.\n",
            "Actual translation: Il est poète. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: This is awesome.\n",
            "Predicted translation: c'est fantastique !\n",
            "Actual translation: C'est fantastique ! <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: How's your wife?\n",
            "Predicted translation: comment va ta femme ?\n",
            "Actual translation: Comment va ta femme ? <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: I'm tired.\n",
            "Predicted translation: je suis fatigué !\n",
            "Actual translation: Je suis fatigué ! <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: He likes to hunt.\n",
            "Predicted translation: il aime chasser.\n",
            "Actual translation: Il aime chasser. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: That's not mine.\n",
            "Predicted translation: ce n'est pas à moi.\n",
            "Actual translation: Ce n'est pas à moi. <eos>\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input sentence: I'm thorough.\n",
            "Predicted translation: je suis minutieux.\n",
            "Actual translation: Je suis consciencieuse. <eos>\n",
            "Continue? [Y/n]n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBQu1JppTh1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}