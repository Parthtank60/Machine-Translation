{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Translation.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jCzRMdEMMXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxBmQ9JCMSng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9e953aee-56a7-4a83-eb39-56cb77bc7d24"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA9SZok-MgI2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "e1e9a6b1-5b75-4f58-9449-ced0efc87710"
      },
      "source": [
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Barrons-800.gdoc\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            " Content-Based-Video-Search-TCS.zip\n",
            "'datasets links'\n",
            " fra.txt\n",
            "'[GigaCourse.com] Udemy - Deep Learning and Computer Vision A-Zâ„¢ OpenCV, SSD & GANs'\n",
            " glove.6B.100d.txt\n",
            " gre\n",
            "'How to get started with Drive.pdf'\n",
            " Icons\n",
            " ipgm_project\n",
            " magoos\n",
            "'Mike And Dave Need Wedding Dates (2016) [1080p] [YTS.AG]'\n",
            "'ml resume'\n",
            " project\n",
            "'Research papers (final-year project).gsheet'\n",
            " TCS_PROJECT\n",
            " Untitled0.ipynb\n",
            "'Untitled document.gdoc'\n",
            "'Untitled spreadsheet.gsheet'\n",
            " videos\n",
            " YOLOv3-Object-Detection-with-OpenCV\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IwP5Ox1MT6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # https://deeplearningcourses.com/c/deep-learning-advanced-nlp\n",
        "# get the data at: http://www.manythings.org/anki/\n",
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "# Note: you may need to update your version of future\n",
        "# sudo pip install -U future\n",
        "\n",
        "import os, sys\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras.backend as K\n",
        "# if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
        "#   from keras.layers import CuDNNLSTM as LSTM\n",
        "#   from keras.layers import CuDNNGRU as GRU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmYpBUQIMMXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some config\n",
        "BATCH_SIZE = 64  # Batch size for training.\n",
        "EPOCHS = 40  # Number of epochs to train for.\n",
        "LATENT_DIM = 256  # Latent dimensionality of the encoding space.\n",
        "NUM_SAMPLES = 10000  # Number of samples to train on.\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "# Where we will store the data\n",
        "input_texts = [] # sentence in original language\n",
        "target_texts = [] # sentence in target language\n",
        "target_texts_inputs = [] # sentence in target language offset by 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynchSkO6MMXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e77b6e7f-4fbb-4c36-c278-943082a43ab8"
      },
      "source": [
        "\n",
        "# load in the data\n",
        "# download the data at: http://www.manythings.org/anki/\n",
        "t = 0\n",
        "for line in open('/content/drive/My Drive/fra.txt'):\n",
        "  # only keep a limited number of samples\n",
        "  t += 1\n",
        "  if t > NUM_SAMPLES:\n",
        "    break\n",
        "\n",
        "  # input and target are separated by tab\n",
        "  if '\\t' not in line:\n",
        "    continue\n",
        "\n",
        "  # split up the input and translation\n",
        "  input_text, translation, *rest = line.rstrip().split('\\t')\n",
        "\n",
        "  # make the target input and output\n",
        "  # recall we'll be using teacher forcing\n",
        "  target_text = translation + ' <eos>'\n",
        "  target_text_input = '<sos> ' + translation\n",
        "\n",
        "  input_texts.append(input_text)\n",
        "  target_texts.append(target_text)\n",
        "  target_texts_inputs.append(target_text_input)\n",
        "print(\"num samples:\", len(input_texts))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd3A3-ZqMMXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7190f80-641b-4bea-fd4b-1b0b6b5438ac"
      },
      "source": [
        "#  tokenize the inputs\n",
        "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer_inputs.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
        "\n",
        "# get the word to index mapping for input language\n",
        "word2idx_inputs = tokenizer_inputs.word_index\n",
        "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
        "\n",
        "# determine maximum length input sequence\n",
        "max_len_input = max(len(s) for s in input_sequences)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2146 unique input tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AdyFe0oMMXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53fc6648-111d-4105-9cdf-1473b5408c35"
      },
      "source": [
        "# tokenize the outputs\n",
        "# don't filter out special characters\n",
        "# otherwise <sos> and <eos> won't appear\n",
        "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
        "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
        "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
        "\n",
        "# get the word to index mapping for output language\n",
        "word2idx_outputs = tokenizer_outputs.word_index\n",
        "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
        "\n",
        "# store number of output words for later\n",
        "# remember to add 1 since indexing starts at 1\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "\n",
        "# determine maximum length output sequence\n",
        "max_len_target = max(len(s) for s in target_sequences)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5754 unique output tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhCqmsR7MMXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b04f1da6-d4cf-4b73-938c-ff3f932a589d"
      },
      "source": [
        "# pad the sequences\n",
        "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
        "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
        "print(\"encoder_inputs[0]:\", encoder_inputs[0])\n",
        "\n",
        "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
        "print(\"decoder_inputs[0]:\", decoder_inputs[0])\n",
        "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
        "\n",
        "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_inputs.shape: (10000, 5)\n",
            "encoder_inputs[0]: [ 0  0  0  0 15]\n",
            "decoder_inputs[0]: [ 2 57  4  0  0  0  0  0  0  0  0]\n",
            "decoder_inputs.shape: (10000, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfKwabYbMMXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e833c101-f9ac-4f86-be25-d2a17c5e7385"
      },
      "source": [
        "\n",
        "# store all the pre-trained word vectors\n",
        "print('Loading word vectors...')\n",
        "word2vec = {}\n",
        "with open('/content/drive/My Drive/glove.6B.100d.txt') as f:\n",
        "  # is just a space-separated text file in the format:\n",
        "  # word vec[0] vec[1] vec[2] ...\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word vectors...\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-mfAAd6MMX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f5b4ac0-1367-40ab-d6ad-dc7ea59467db"
      },
      "source": [
        "\n",
        "# prepare embedding matrix\n",
        "print('Filling pre-trained embeddings...')\n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word2idx_inputs.items():\n",
        "  if i < MAX_NUM_WORDS:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filling pre-trained embeddings...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1ez8eUWMMX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create embedding layer\n",
        "embedding_layer = Embedding(\n",
        "  num_words,\n",
        "  EMBEDDING_DIM,\n",
        "  weights=[embedding_matrix],\n",
        "  input_length=max_len_input,\n",
        "  # trainable=True\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LgYDs6rMMX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create targets, since we cannot use sparse\n",
        "# categorical cross entropy when we have sequences\n",
        "decoder_targets_one_hot = np.zeros(\n",
        "  (\n",
        "    len(input_texts),\n",
        "    max_len_target,\n",
        "    num_words_output\n",
        "  ),\n",
        "  dtype='float32'\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q774k8p8MMX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assign the values\n",
        "for i, d in enumerate(decoder_targets):\n",
        "  for t, word in enumerate(d):\n",
        "    if word != 0:\n",
        "      decoder_targets_one_hot[i, t, word] = 1\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Nr7-db2MMX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71b840ee-8f86-4037-af81-9c4e9ed1f78c"
      },
      "source": [
        "decoder_targets_one_hot.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 11, 5755)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sP2ZXYzMMYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "668634fa-2e18-449e-bb27-b4ef796aa1a2"
      },
      "source": [
        "##### build the model #####\n",
        "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "print(x.shape)\n",
        "encoder = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_state=True,\n",
        "  dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "# print(encoder.shape)\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "print(encoder_outputs.shape)\n",
        "print(h.shape)\n",
        "print(c.shape)\n",
        "\n",
        "# encoder_outputs, h = encoder(x) #gru\n",
        "\n",
        "# keep only the states to pass into decoder\n",
        "encoder_states = [h, c]\n",
        "# print(encoder_states.shape)\n",
        "# encoder_states = [state_h] # gru\n",
        "\n",
        "# Set up the decoder, using [h, c] as initial state.\n",
        "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
        "\n",
        "# this word embedding will not use pre-trained vectors\n",
        "# although you could\n",
        "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "print(decoder_inputs_x)\n",
        "# since the decoder is a \"to-many\" model we want to have\n",
        "# return_sequences=True\n",
        "decoder_lstm = LSTM(\n",
        "  LATENT_DIM,\n",
        "  return_sequences=True,\n",
        "  return_state=True,\n",
        "  # dropout=0.5 # dropout not available on gpu\n",
        ")\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "  decoder_inputs_x,\n",
        "  initial_state=encoder_states\n",
        ")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 5, 100)\n",
            "(None, 256)\n",
            "(None, 256)\n",
            "(None, 256)\n",
            "Tensor(\"embedding_2/embedding_lookup/Identity_1:0\", shape=(None, 11, 100), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K2SO1LEMMYE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6857e21-d284-471e-c507-db85343a9ead"
      },
      "source": [
        "# final dense layer for predictions\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "# print(decoder_dense.shape)\n",
        "print(decoder_outputs.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 11, 5755)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id3C3HUOMMYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model object\n",
        "model = Model([encoder_inputs_placeholder, decoder_inputs_placeholder], decoder_outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIT-OVfUMMYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "  # both are of shape N x T x K\n",
        "  mask = K.cast(y_true > 0, dtype='float32')\n",
        "  out = mask * y_true * K.log(y_pred)\n",
        "  return -K.sum(out) / K.sum(mask)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyGD8ef2MMYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(y_true, y_pred):\n",
        "  # both are of shape N x T x K\n",
        "  targ = K.argmax(y_true, axis=-1)\n",
        "  pred = K.argmax(y_pred, axis=-1)\n",
        "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
        "\n",
        "  # 0 is padding, don't include those\n",
        "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
        "  n_correct = K.sum(mask * correct)\n",
        "  n_total = K.sum(mask)\n",
        "  return n_correct / n_total\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWNcFWZMMYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naNiOBLYMMYR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7c7fbd11-6c38-4d0d-ca4e-50f4b744df13"
      },
      "source": [
        "r = model.fit(\n",
        "  [encoder_inputs, decoder_inputs], decoder_targets_one_hot,\n",
        "  batch_size=BATCH_SIZE,\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2,\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/40\n",
            "8000/8000 [==============================] - 14s 2ms/step - loss: 5.6565 - acc: 0.2603 - val_loss: 5.3085 - val_acc: 0.2491\n",
            "Epoch 2/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 4.6370 - acc: 0.2900 - val_loss: 5.1175 - val_acc: 0.2626\n",
            "Epoch 3/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 4.2876 - acc: 0.3145 - val_loss: 4.9381 - val_acc: 0.2971\n",
            "Epoch 4/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 3.9433 - acc: 0.3665 - val_loss: 4.7624 - val_acc: 0.3267\n",
            "Epoch 5/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 3.6758 - acc: 0.4056 - val_loss: 4.6571 - val_acc: 0.3431\n",
            "Epoch 6/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 3.4438 - acc: 0.4346 - val_loss: 4.5931 - val_acc: 0.3592\n",
            "Epoch 7/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 3.2334 - acc: 0.4574 - val_loss: 4.5109 - val_acc: 0.3731\n",
            "Epoch 8/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 3.0462 - acc: 0.4780 - val_loss: 4.4692 - val_acc: 0.3870\n",
            "Epoch 9/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 2.8784 - acc: 0.4921 - val_loss: 4.4206 - val_acc: 0.3961\n",
            "Epoch 10/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 2.7252 - acc: 0.5078 - val_loss: 4.3890 - val_acc: 0.3954\n",
            "Epoch 11/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 2.5862 - acc: 0.5224 - val_loss: 4.3585 - val_acc: 0.4134\n",
            "Epoch 12/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 2.4592 - acc: 0.5339 - val_loss: 4.3609 - val_acc: 0.4209\n",
            "Epoch 13/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 2.3359 - acc: 0.5456 - val_loss: 4.3244 - val_acc: 0.4248\n",
            "Epoch 14/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 2.2236 - acc: 0.5587 - val_loss: 4.3268 - val_acc: 0.4289\n",
            "Epoch 15/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 2.1231 - acc: 0.5684 - val_loss: 4.3489 - val_acc: 0.4308\n",
            "Epoch 16/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 2.0271 - acc: 0.5806 - val_loss: 4.3369 - val_acc: 0.4374\n",
            "Epoch 17/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.9380 - acc: 0.5905 - val_loss: 4.3584 - val_acc: 0.4419\n",
            "Epoch 18/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.8530 - acc: 0.6011 - val_loss: 4.3679 - val_acc: 0.4435\n",
            "Epoch 19/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.7735 - acc: 0.6099 - val_loss: 4.3913 - val_acc: 0.4466\n",
            "Epoch 20/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.7025 - acc: 0.6179 - val_loss: 4.3885 - val_acc: 0.4532\n",
            "Epoch 21/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.6293 - acc: 0.6287 - val_loss: 4.4059 - val_acc: 0.4537\n",
            "Epoch 22/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.5661 - acc: 0.6384 - val_loss: 4.4086 - val_acc: 0.4571\n",
            "Epoch 23/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.5023 - acc: 0.6472 - val_loss: 4.4250 - val_acc: 0.4547\n",
            "Epoch 24/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.4429 - acc: 0.6546 - val_loss: 4.4439 - val_acc: 0.4549\n",
            "Epoch 25/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.3865 - acc: 0.6622 - val_loss: 4.4497 - val_acc: 0.4580\n",
            "Epoch 26/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.3335 - acc: 0.6734 - val_loss: 4.4631 - val_acc: 0.4585\n",
            "Epoch 27/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.2849 - acc: 0.6789 - val_loss: 4.4820 - val_acc: 0.4584\n",
            "Epoch 28/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.2356 - acc: 0.6867 - val_loss: 4.5203 - val_acc: 0.4567\n",
            "Epoch 29/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 1.1908 - acc: 0.6951 - val_loss: 4.5215 - val_acc: 0.4592\n",
            "Epoch 30/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 1.1473 - acc: 0.7012 - val_loss: 4.5255 - val_acc: 0.4608\n",
            "Epoch 31/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 1.1072 - acc: 0.7079 - val_loss: 4.5329 - val_acc: 0.4624\n",
            "Epoch 32/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.0670 - acc: 0.7159 - val_loss: 4.5754 - val_acc: 0.4579\n",
            "Epoch 33/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 1.0288 - acc: 0.7203 - val_loss: 4.5889 - val_acc: 0.4625\n",
            "Epoch 34/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 0.9971 - acc: 0.7271 - val_loss: 4.6029 - val_acc: 0.4627\n",
            "Epoch 35/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 0.9601 - acc: 0.7318 - val_loss: 4.6148 - val_acc: 0.4646\n",
            "Epoch 36/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 0.9261 - acc: 0.7385 - val_loss: 4.6388 - val_acc: 0.4619\n",
            "Epoch 37/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 0.8965 - acc: 0.7447 - val_loss: 4.6669 - val_acc: 0.4637\n",
            "Epoch 38/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 0.8663 - acc: 0.7489 - val_loss: 4.6432 - val_acc: 0.4660\n",
            "Epoch 39/40\n",
            "8000/8000 [==============================] - 11s 1ms/step - loss: 0.8368 - acc: 0.7553 - val_loss: 4.6902 - val_acc: 0.4638\n",
            "Epoch 40/40\n",
            "8000/8000 [==============================] - 12s 1ms/step - loss: 0.8106 - acc: 0.7584 - val_loss: 4.6764 - val_acc: 0.4658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fqW7kScMMYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "76fdf203-a775-4791-bbab-0a03b3b449ba"
      },
      "source": [
        "# plot some data\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP-5CJvLSZeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ef5114ab-2fb4-48a2-a766-9e1b3bd4ce48"
      },
      "source": [
        "# accuracies\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a0a7d784daeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvyNTs85ScOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u251TjyHSijR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Make predictions #####\n",
        "# As with the poetry example, we need to create another model\n",
        "# that can take in the RNN state and previous word as input\n",
        "# and accept a T=1 sequence.\n",
        "\n",
        "# The encoder will be stand-alone\n",
        "# From this we will get our initial decoder hidden state\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(LATENT_DIM,))\n",
        "decoder_state_input_c = Input(shape=(LATENT_DIM,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# decoder_states_inputs = [decoder_state_input_h] # gru\n",
        "\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "\n",
        "# this time, we want to keep the states too, to be output\n",
        "# by our sampling model\n",
        "decoder_outputs, h, c = decoder_lstm(\n",
        "  decoder_inputs_single_x,\n",
        "  initial_state=decoder_states_inputs\n",
        ")\n",
        "# decoder_outputs, state_h = decoder_lstm(\n",
        "#   decoder_inputs_single_x,\n",
        "#   initial_state=decoder_states_inputs\n",
        "# ) #gru\n",
        "decoder_states = [h, c]\n",
        "# decoder_states = [h] # gru\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnw6dDjkSoqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The sampling model\n",
        "# inputs: y(t-1), h(t-1), c(t-1)\n",
        "# outputs: y(t), h(t), c(t)\n",
        "decoder_model = Model(\n",
        "  [decoder_inputs_single] + decoder_states_inputs, \n",
        "  [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# map indexes back into real words\n",
        "# so we can view the results\n",
        "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vDeCd5-SsDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # Encode the input as state vectors.\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1, 1))\n",
        "\n",
        "  # Populate the first character of target sequence with the start character.\n",
        "  # NOTE: tokenizer lower-cases all words\n",
        "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "\n",
        "  # if we get this we break\n",
        "  eos = word2idx_outputs['<eos>']\n",
        "\n",
        "  # Create the translation\n",
        "  output_sentence = []\n",
        "  for _ in range(max_len_target):\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "      [target_seq] + states_value\n",
        "    )\n",
        "    # output_tokens, h = decoder_model.predict(\n",
        "    #     [target_seq] + states_value\n",
        "    # ) # gru\n",
        "\n",
        "    # Get next word\n",
        "    idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "    # End sentence of EOS\n",
        "    if eos == idx:\n",
        "      break\n",
        "\n",
        "    word = ''\n",
        "    if idx > 0:\n",
        "      word = idx2word_trans[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "    # Update the decoder input\n",
        "    # which is just the word just generated\n",
        "    target_seq[0, 0] = idx\n",
        "\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "    # states_value = [h] # gru\n",
        "\n",
        "  return ' '.join(output_sentence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64vo4EVwSxQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "68bae86b-d48b-4130-b945-7eb73d2e9e56"
      },
      "source": [
        "while True:\n",
        "  # Do some test translations\n",
        "  i = np.random.choice(len(input_texts))\n",
        "  input_seq = encoder_inputs[i:i+1]\n",
        "  translation = decode_sequence(input_seq)\n",
        "  print('-')\n",
        "  print('Input:', input_texts[i])\n",
        "  print('Translation:', translation)\n",
        "\n",
        "  ans = input(\"Continue? [Y/n]\")\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "    break"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: I'm happy, too.\n",
            "Translation: je suis Ã©galement affairÃ©e.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: I didn't look.\n",
            "Translation: je n'ai pas regardÃ©.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: May I come in?\n",
            "Translation: puis-je entrer ?\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: I'm involved.\n",
            "Translation: je suis impliquÃ©e.\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: Who is there?\n",
            "Translation: qui est lÃ  ?\n",
            "Continue? [Y/n]Y\n",
            "-\n",
            "Input: How's it going?\n",
            "Translation: comment cela se passe-t-il ?\n",
            "Continue? [Y/n]n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biqnx22YS0IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}